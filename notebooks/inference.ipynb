{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c4535b",
   "metadata": {},
   "source": [
    "# Inference using the SLAP models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d90127",
   "metadata": {},
   "source": [
    "Predict reaction outcome for morpholine/piperazine products.\n",
    "\n",
    "For most requirements, using the command-line interface (`inference.py`) will be faster/simpler than using this notebook. But if you want to change things or have a look under the hood, feel free to use this notebook.\n",
    "\n",
    "The input to this are SMILES of the desired product(s).\n",
    "Inputs can be supplied directly as a csv file with one column named \"smiles\" and arbitrary additional columns.\n",
    "\n",
    "The output is:\n",
    "- all (one or two) reactionSMILES that lead to this product using the SLAP platform\n",
    "- for each reaction, a classification of whether the reaction is expected to work\n",
    "- for each reaction, a rough estimate of the confidence for this prediction\n",
    "\n",
    "The output is written to a new csv file containing all columns from the input file, and six new columns: `rxn1_smiles`, `rxn1_prediction`, `rxn1_confidence`, `rxn2_smiles`, `rxn2_prediction`, `rxn2_confidence`.\n",
    "\n",
    "Columns `rxn2_*` may have empty fields.\n",
    "\n",
    "Predictions are given as `0` (meaning no reaction expected) or `1` (meaning successful reaction expected). Only if the reaction is known, instead of the prediction, the mean of the known reaction outcome(s) is returned.\n",
    "Confidence is given as an integer in the range `0-4`, with `0` indicating the highest confidence.\n",
    "Confidence is determined based on the complexity of the prediction problem using the following heuristic:\n",
    "- `0`: known reactions\n",
    "- `1`: both reactants known in other reactions\n",
    "- `2`: exactly one reactant known in other reactions\n",
    "- `3`: unknown reactants, similar to training data\n",
    "- `4`: unknown reactants, dissimilar to training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83b22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import statistics\n",
    "import sys\n",
    "sys.path.append(str(pathlib.Path(\"__file__\").absolute().parents[1]))\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.util.definitions import TRAINED_MODEL_DIR, LOG_DIR\n",
    "from inference import import_valid_smiles_from_vl\n",
    "from src.model.classifier import load_trained_model\n",
    "from src.data.dataloader import SLAPProductDataset, collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79eb05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_validation_data = True  # <-- Whether to use models also trained on validation plate data, toggle this to change the models used\n",
    "\n",
    "# paths to the best models\n",
    "if use_validation_data:\n",
    "    # the next three are trained with full data, including validation plate data\n",
    "    model_0D = TRAINED_MODEL_DIR / \"2023-03-06-105610_484882\" / \"best.ckpt\"  # FFN\n",
    "    model_1D = TRAINED_MODEL_DIR / \"2023-03-06-112027_188465\" / \"best.ckpt\"  # D-MPNN\n",
    "    model_2D = TRAINED_MODEL_DIR / \"2023-03-06-112721_778803\" / \"best.ckpt\"  # D-MPNN\n",
    "    # path to the OneHotEncoder state for model_0D\n",
    "    ohe_state_dict = LOG_DIR / \"OHE_state_dict_bhTczANzKRRqIgUR.json\"  # with validation plate data\n",
    "\n",
    "else:\n",
    "    # the next three are trained without using validation plate data\n",
    "    model_0D = TRAINED_MODEL_DIR / \"2022-12-16-144509_863758\" / \"best.ckpt\"  # FFN\n",
    "    model_1D = TRAINED_MODEL_DIR / \"2022-12-16-145840_448790\" / \"best.ckpt\"  # D-MPNN\n",
    "    model_2D = TRAINED_MODEL_DIR / \"2022-12-06-115456_273019\" / \"best.ckpt\"  # D-MPNN\n",
    "    # path to the OneHotEncoder state for model_0D\n",
    "    ohe_state_dict = LOG_DIR / \"OHE_state_dict_FqIDTIsCHoURGQcv.json\"  # without validation plate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e1a3e0",
   "metadata": {},
   "source": [
    "To use the notebook on your products, change `raw_dir` to the directory that your CSV file containing SMILES is in. Then change `filename` to the filename of your csv file (can be compressed in any format Pandas can extract). If you do not want to use all the SMILES in your file (e.g. because some are not valid SLAP products), suppy a `valid_idx_file`. You can set the value to `None` if you want to use all SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ac6857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not generate reaction for product with index 1200. Using dummy reaction.\n",
      "Error leading to this warning: More than two possible reactions found.\n",
      "WARNING: Could not generate reaction for product with index 6194. Using dummy reaction.\n",
      "Error leading to this warning: Encountered RuntimeError while generating reaction for product 'COc1cc(C2COC(C)C(C3CC[Si](C)(C)C3)N2)ccc1SC'.\n",
      "Original error message: More than one reaction found for SLAP reagent 'CC(OC[Si](C)(C)C)C(N)C1CC[Si](C)(C)C1' and aldehyde 'COc1cc(C=O)ccc1SC'.\n",
      "Reactions:\n",
      "C[Si]1(C)[CH2:8][CH2:7][CH:6]([CH:4]([CH:3]([CH3:18])[O:19][CH2:20][Si:21]([CH3:22])([CH3:23])[CH3:24])[NH2:5])[CH2:25]1.O=[CH:2][c:1]1[cH:9][c:11]([O:13][CH3:15])[c:14]([S:16][CH3:17])[cH:12][cH:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH:3]([CH3:18])[O:19][CH2:20][Si:21]([CH3:22])([CH3:23])[CH3:24])[CH:6]([CH3:25])[CH2:7][CH2:8]2)[cH:9][c:11]([O:13][CH3:15])[c:14]([S:16][CH3:17])[cH:12][cH:10]1\n",
      "C[Si](C)(C)[CH2:8][O:7][CH:6]([CH:4]([CH:3]1[CH2:18][CH2:20][Si:21]([CH3:22])([CH3:23])[CH2:19]1)[NH2:5])[CH3:24].O=[CH:2][c:1]1[cH:9][c:11]([O:13][CH3:15])[c:14]([S:16][CH3:17])[cH:12][cH:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH:3]3[CH2:18][CH2:20][Si:21]([CH3:22])([CH3:23])[CH2:19]3)[CH:6]([CH3:24])[O:7][CH2:8]2)[cH:9][c:11]([O:13][CH3:15])[c:14]([S:16][CH3:17])[cH:12][cH:10]1\n",
      "WARNING: Could not generate reaction for product with index 7636. Using dummy reaction.\n",
      "Error leading to this warning: Encountered RuntimeError while generating reaction for product 'CC(CC1COCC(c2cc(C(C)(C)C)ccn2)N1)C[Si](C)(C)C'.\n",
      "Original error message: More than one reaction found for SLAP reagent 'CC(CC(N)COC[Si](C)(C)C)C[Si](C)(C)C' and aldehyde 'CC(C)(C)c1ccnc(C=O)c1'.\n",
      "Reactions:\n",
      "C[Si](C)(C)[CH2:8][CH:7]([CH2:6][CH:4]([CH2:3][O:18][CH2:19][Si:20]([CH3:21])([CH3:22])[CH3:23])[NH2:5])[CH3:24].O=[CH:2][c:1]1[cH:9][c:11]([C:13]([CH3:15])([CH3:16])[CH3:17])[cH:14][cH:12][n:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH2:3][O:18][CH2:19][Si:20]([CH3:21])([CH3:22])[CH3:23])[CH2:6][CH:7]([CH3:24])[CH2:8]2)[cH:9][c:11]([C:13]([CH3:15])([CH3:16])[CH3:17])[cH:14][cH:12][n:10]1\n",
      "C[Si](C)(C)[CH2:8][O:7][CH2:6][CH:4]([CH2:3][CH:18]([CH3:19])[CH2:20][Si:21]([CH3:22])([CH3:23])[CH3:24])[NH2:5].O=[CH:2][c:1]1[cH:9][c:11]([C:13]([CH3:15])([CH3:16])[CH3:17])[cH:14][cH:12][n:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH2:3][CH:18]([CH3:19])[CH2:20][Si:21]([CH3:22])([CH3:23])[CH3:24])[CH2:6][O:7][CH2:8]2)[cH:9][c:11]([C:13]([CH3:15])([CH3:16])[CH3:17])[cH:14][cH:12][n:10]1\n",
      "WARNING: Could not generate reaction for product with index 8033. Using dummy reaction.\n",
      "Error leading to this warning: Encountered RuntimeError while generating reaction for product 'COc1cc(C2COCC(CC(C)C[Si](C)(C)C)N2)cc(O)c1O'.\n",
      "Original error message: More than one reaction found for SLAP reagent 'CC(CC(N)COC[Si](C)(C)C)C[Si](C)(C)C' and aldehyde 'COc1cc(C=O)cc(O)c1O'.\n",
      "Reactions:\n",
      "C[Si](C)(C)[CH2:8][CH:7]([CH2:6][CH:4]([CH2:3][O:18][CH2:19][Si:20]([CH3:21])([CH3:22])[CH3:23])[NH2:5])[CH3:24].O=[CH:2][c:1]1[cH:9][c:11]([O:13][CH3:16])[c:14]([OH:17])[c:12]([OH:15])[cH:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH2:3][O:18][CH2:19][Si:20]([CH3:21])([CH3:22])[CH3:23])[CH2:6][CH:7]([CH3:24])[CH2:8]2)[cH:9][c:11]([O:13][CH3:16])[c:14]([OH:17])[c:12]([OH:15])[cH:10]1\n",
      "C[Si](C)(C)[CH2:8][O:7][CH2:6][CH:4]([CH2:3][CH:18]([CH3:19])[CH2:20][Si:21]([CH3:22])([CH3:23])[CH3:24])[NH2:5].O=[CH:2][c:1]1[cH:9][c:11]([O:13][CH3:16])[c:14]([OH:17])[c:12]([OH:15])[cH:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH2:3][CH:18]([CH3:19])[CH2:20][Si:21]([CH3:22])([CH3:23])[CH3:24])[CH2:6][O:7][CH2:8]2)[cH:9][c:11]([O:13][CH3:16])[c:14]([OH:17])[c:12]([OH:15])[cH:10]1\n",
      "WARNING: Could not generate reaction for product with index 9339. Using dummy reaction.\n",
      "Error leading to this warning: Encountered RuntimeError while generating reaction for product 'CC1(C)OCC(c2cccc(-c3ccccc3)c2)NC1C1CC[Si](C)(C)C1'.\n",
      "Original error message: More than one reaction found for SLAP reagent 'CC(C)(OC[Si](C)(C)C)C(N)C1CC[Si](C)(C)C1' and aldehyde 'O=Cc1cccc(-c2ccccc2)c1'.\n",
      "Reactions:\n",
      "C[Si]1(C)[CH2:8][CH2:7][CH:6]([CH:4]([C:3]([CH3:20])([CH3:21])[O:22][CH2:23][Si:24]([CH3:25])([CH3:26])[CH3:27])[NH2:5])[CH2:28]1.O=[CH:2][c:1]1[cH:9][cH:11][cH:13][c:12](-[c:14]2[cH:15][cH:17][cH:19][cH:18][cH:16]2)[cH:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([C:3]([CH3:20])([CH3:21])[O:22][CH2:23][Si:24]([CH3:25])([CH3:26])[CH3:27])[CH:6]([CH3:28])[CH2:7][CH2:8]2)[cH:9][cH:11][cH:13][c:12](-[c:14]2[cH:15][cH:17][cH:19][cH:18][cH:16]2)[cH:10]1\n",
      "C[Si](C)(C)[CH2:8][O:7][C:6]([CH:4]([CH:3]1[CH2:20][CH2:22][Si:23]([CH3:24])([CH3:25])[CH2:21]1)[NH2:5])([CH3:26])[CH3:27].O=[CH:2][c:1]1[cH:9][cH:11][cH:13][c:12](-[c:14]2[cH:15][cH:17][cH:19][cH:18][cH:16]2)[cH:10]1>>[c:1]1([CH:2]2[NH:5][CH:4]([CH:3]3[CH2:20][CH2:22][Si:23]([CH3:24])([CH3:25])[CH2:21]3)[C:6]([CH3:26])([CH3:27])[O:7][CH2:8]2)[cH:9][cH:11][cH:13][c:12](-[c:14]2[cH:15][cH:17][cH:19][cH:18][cH:16]2)[cH:10]1\n",
      "WARNING: Could not generate reaction for product with index 9490. Using dummy reaction.\n",
      "Error leading to this warning: Encountered RuntimeError while generating reaction for product 'Cc1cnc(C2COC(C)C(C3CC[Si](C)(C)C3)N2)c(C)c1'.\n",
      "Original error message: More than one reaction found for SLAP reagent 'CC(OC[Si](C)(C)C)C(N)C1CC[Si](C)(C)C1' and aldehyde 'Cc1cnc(C=O)c(C)c1'.\n",
      "Reactions:\n",
      "C[Si]1(C)[CH2:8][CH2:7][CH:6]([CH:4]([CH:3]([CH3:16])[O:17][CH2:18][Si:19]([CH3:20])([CH3:21])[CH3:22])[NH2:5])[CH2:23]1.O=[CH:2][c:1]1[n:9][cH:11][c:14]([CH3:15])[cH:13][c:10]1[CH3:12]>>[c:1]1([CH:2]2[NH:5][CH:4]([CH:3]([CH3:16])[O:17][CH2:18][Si:19]([CH3:20])([CH3:21])[CH3:22])[CH:6]([CH3:23])[CH2:7][CH2:8]2)[n:9][cH:11][c:14]([CH3:15])[cH:13][c:10]1[CH3:12]\n",
      "C[Si](C)(C)[CH2:8][O:7][CH:6]([CH:4]([CH:3]1[CH2:16][CH2:18][Si:19]([CH3:20])([CH3:21])[CH2:17]1)[NH2:5])[CH3:22].O=[CH:2][c:1]1[n:9][cH:11][c:14]([CH3:15])[cH:13][c:10]1[CH3:12]>>[c:1]1([CH:2]2[NH:5][CH:4]([CH:3]3[CH2:16][CH2:18][Si:19]([CH3:20])([CH3:21])[CH2:17]3)[CH:6]([CH3:22])[O:7][CH2:8]2)[n:9][cH:11][c:14]([CH3:15])[cH:13][c:10]1[CH3:12]\n",
      "INFO: 10000 SMILES were read. For 6 SMILES, no valid SLAP reaction could be generated.\n"
     ]
    }
   ],
   "source": [
    "# Import product SMILES and generate reactionSMILES. This will take some time.\n",
    "# This will throw warnings if any reactions cannot be generated, \n",
    "# e.g. if there are two morpholines in the same product.\n",
    "raw_dir = pathlib.Path(\"../data/VL\")  # <-- change me\n",
    "filename = \"VL_chunk_0000_smiles.csv.bz2\"  # <-- change me\n",
    "# remove the .csv extension AND any other extensions behind it (e.g. remove .csv.bz2 or csv.gz)\n",
    "filename_base = filename.split(\".csv\")[0]\n",
    "valid_idx_file = None  # <-- change me or set me to None\n",
    "df = import_valid_smiles_from_vl(raw_dir, filename, valid_idx_file=valid_idx_file)\n",
    "data = SLAPProductDataset(smiles=df[\"smiles\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069d3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data. This includes generating reaction graphs and takes some time.\n",
    "\n",
    "data.process({\"dataset_0D\": dict(\n",
    "    reaction=True, \n",
    "    global_features=[\"OHE\",],\n",
    "    global_featurizer_state_dict_path=ohe_state_dict,\n",
    "    graph_type=\"bond_edges\", \n",
    "    featurizers=\"custom\",\n",
    "),\n",
    "             \"dataset_1D_slap\": dict(\n",
    "    reaction=True, \n",
    "    global_features=None, \n",
    "    graph_type=\"bond_nodes\", \n",
    "    featurizers=\"custom\",\n",
    "),\n",
    "              \"dataset_1D_aldehyde\": dict(\n",
    "    reaction=True, \n",
    "    global_features=None, \n",
    "    graph_type=\"bond_nodes\", \n",
    "    featurizers=\"custom\",\n",
    "),\n",
    "              \"dataset_2D\": dict(\n",
    "    reaction=True, \n",
    "    global_features=None, \n",
    "    graph_type=\"bond_nodes\", \n",
    "    featurizers=\"custom\",\n",
    "),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dbf0d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/miniconda3/envs/slap-platform-prediction/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/julian/miniconda3/envs/slap-platform-prediction/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9016d1287470f9f2a9fe0582ce698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67476044a0834c82b349879fb7c0f024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d578abf5f2d94fe7958c164203d8ff08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run all the predictions\n",
    "\n",
    "if data.dataset_0D:\n",
    "    # load the trained model if it is not loaded\n",
    "    if isinstance(model_0D, str) or isinstance(model_0D, pathlib.Path):\n",
    "        model_0D = load_trained_model(\"FFN\", model_0D)\n",
    "        model_0D.eval()\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", logger=False, max_epochs=-1)\n",
    "    dl = DataLoader(data.dataset_0D, collate_fn=collate_fn)\n",
    "    probabilities_0D = torch.concat(trainer.predict(model_0D, dl))\n",
    "    predictions_0D = (probabilities_0D > 0.5).numpy().astype(float)\n",
    "    \n",
    "\n",
    "if data.dataset_1D_aldehyde:\n",
    "    # load the trained model if it is not loaded\n",
    "    if isinstance(model_1D, str) or isinstance(model_1D, pathlib.Path):\n",
    "        model_1D = load_trained_model(\"D-MPNN\", model_1D)\n",
    "        model_1D.eval()\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", logger=False, max_epochs=-1)\n",
    "    dl = DataLoader(data.dataset_1D_aldehyde, collate_fn=collate_fn)\n",
    "    probabilities_1D_aldehyde = torch.concat(trainer.predict(model_1D, dl))\n",
    "    predictions_1D_aldehyde = (probabilities_1D_aldehyde > 0.5).numpy().astype(float)\n",
    "\n",
    "if data.dataset_1D_slap:\n",
    "    # load the trained model if it is not loaded\n",
    "    if isinstance(model_1D, str) or isinstance(model_1D, pathlib.Path):\n",
    "        model_1D = load_trained_model(\"D-MPNN\", model_1D)\n",
    "        model_1D.eval()\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", logger=False, max_epochs=-1)\n",
    "    dl = DataLoader(data.dataset_1D_slap, collate_fn=collate_fn)\n",
    "    probabilities_1D_slap = torch.concat(trainer.predict(model_1D, dl))\n",
    "    predictions_1D_slap = (probabilities_1D_slap > 0.5).numpy().astype(float)\n",
    "\n",
    "if data.dataset_2D:\n",
    "    # load the trained model if it is not loaded\n",
    "    if isinstance(model_2D, str) or isinstance(model_2D, pathlib.Path):\n",
    "        model_2D = load_trained_model(\"D-MPNN\", model_2D)\n",
    "        model_2D.eval()\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", logger=False, max_epochs=-1)\n",
    "    dl = DataLoader(data.dataset_2D, collate_fn=collate_fn)\n",
    "    probabilities_2D = torch.concat(trainer.predict(model_2D, dl))\n",
    "    predictions_2D = (probabilities_2D > 0.5).numpy().astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89faead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble outputs\n",
    "predictions = np.full(len(data.reactions), np.nan, dtype=float)\n",
    "\n",
    "predictions[data.idx_known] = [statistics.mean(data.known_outcomes[i]) for i in data.idx_known]  # for known reaction we add the average reaction outcome\n",
    "try:\n",
    "    predictions[data.idx_0D] = predictions_0D\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    predictions[data.idx_1D_slap] = predictions_1D_slap\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    predictions[data.idx_1D_aldehyde] = predictions_1D_aldehyde\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    predictions[data.idx_2D] = predictions_2D\n",
    "except NameError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13c63465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have not predicted for anything\n",
    "# this should be only the reactions in data.invalid_idxs\n",
    "rxn_idxs_no_pred = np.argwhere(np.isnan(predictions)).flatten()\n",
    "\n",
    "rxn_idxs_invalid = [data.product_idxs.index(i) for i in data.invalid_idxs]\n",
    "\n",
    "assert set(rxn_idxs_no_pred) == set(rxn_idxs_invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ea6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 1D- product_idxs to the directionally reverse 2D indices\n",
    "arr = np.full((len(data.smiles), 2), fill_value=-1)\n",
    "last_idx = -1\n",
    "for i, idx in enumerate(data.product_idxs):\n",
    "    if idx == last_idx:\n",
    "        arr[idx, 1] = i\n",
    "    else:\n",
    "        last_idx = idx\n",
    "        arr[idx, 0] = i\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d67ad65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_dict = {\n",
    "    \"known\": 0,\n",
    "    \"0D\": 1,\n",
    "    \"1D_SLAP\": 2,\n",
    "    \"1D_aldehyde\": 2,\n",
    "    \"2D_similar\": 3,\n",
    "    \"2D_dissimilar\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4bd3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate problem type to integer\n",
    "rxn_problem_types = list(map(confidence_dict.get, data.problem_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbeea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add a nonsense value to the end of each of these lists so that indexing with -1 will return the nonsense value\n",
    "reactions_augmented = data.reactions + [\"\"]\n",
    "predictions_augmented = list(predictions) + [np.nan]\n",
    "rxn_problem_types_augmented = rxn_problem_types + [99]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3c78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain individual new columns for output df\n",
    "df[\"rxn1_smiles\"] = [data.reactions[i] for i in arr[:,0]]\n",
    "\n",
    "df[\"rxn1_predictions\"] = [predictions[i] for i in arr[:,0]]\n",
    "\n",
    "df[\"rxn1_confidence\"] = [rxn_problem_types[i] for i in arr[:,0]]\n",
    "\n",
    "df[\"rxn2_smiles\"] = [reactions_augmented[i] for i in arr[:,1]]\n",
    "\n",
    "df[\"rxn2_predictions\"] = [predictions_augmented[i] for i in arr[:,1]]\n",
    "\n",
    "df[\"rxn2_confidence\"] = [rxn_problem_types_augmented[i] for i in arr[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59bff6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621 reactions generated from 10000 input SMILES\n",
      "Known reactions: 0\n",
      "0D reactions: 0, thereof 0 predicted positive\n",
      "1D reactions with unknown aldehyde: 55, thereof 31 predicted positive\n",
      "1D reactions with unknown SLAP reagent: 219, thereof 62 predicted positive\n",
      "2D reactions: 15341, thereof 1838 predicted positive\n"
     ]
    }
   ],
   "source": [
    "# write dataset statistics for control to log file (+ optionally print)\n",
    "verbose = True\n",
    "log_output = f\"\"\"\\\n",
    "{len(data.reactions)} reactions generated from {len(data.smiles)} input SMILES\n",
    "Known reactions: {(sum(x is not None for x in data.known_outcomes))}\n",
    "0D reactions: 0, thereof 0 predicted positive\n",
    "1D reactions with unknown aldehyde: {len(data.dataset_1D_aldehyde)}, thereof {np.count_nonzero(predictions_1D_aldehyde)} predicted positive\n",
    "1D reactions with unknown SLAP reagent: {len(data.dataset_1D_slap)}, thereof {np.count_nonzero(predictions_1D_slap)} predicted positive\n",
    "2D reactions: {len(data.dataset_2D)}, thereof {np.count_nonzero(predictions_2D)} predicted positive\n",
    "\"\"\"\n",
    "\n",
    "with open(raw_dir / f\"{filename_base}_reaction_prediction.log\", \"w\") as file:\n",
    "    file.write(log_output)\n",
    "if verbose:\n",
    "    print(log_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec60f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to output file\n",
    "df.to_csv(raw_dir / f\"{filename_base}_reaction_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
