{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43aa7725",
   "metadata": {},
   "source": [
    "# Inference using the SLAP models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91447e",
   "metadata": {},
   "source": [
    "Predict reaction outcome for a single reaction or batch of reactions.\n",
    "\n",
    "The input to this are atom-mapped reactionSMILES. \n",
    "-> note: Ideally we would just put in the target molecule and construct the one or two reactions leading to it.\n",
    "\n",
    "They do not need to be balanced. \n",
    "They can be supplied directly as a txt file with one reactionSMILES per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c1a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "sys.path.append(str(pathlib.Path(\"__file__\").absolute().parents[1]))\n",
    "\n",
    "from src.model.classifier import load_trained_model\n",
    "from src.data.dataloader import SLAPDataset, collate_fn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0473958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "# CHANGE raw_dir and name to the location of your file\n",
    "# expects a file with \"SMILES\" in the first line and one reactionSMILES on each following line\n",
    "data = SLAPDataset(\n",
    "            name=\"reactions.txt\",\n",
    "            raw_dir=\"../data/\",\n",
    "            reaction=True,\n",
    "            graph_type=\"bond_nodes\",\n",
    "            featurizers=\"custom\",\n",
    "            label_column=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43076732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to the best models\n",
    "model_0D = \"tba\"\n",
    "model_1D = \"tba\"\n",
    "model_2D = \"../production_models/2022-12-06-115456_273019/best.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "083921ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/julian/miniconda3/envs/slap-gnn/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011317968368530273,
       "initial": 0,
       "n": 0,
       "ncols": 100,
       "nrows": 24,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16846544af5346a692af54b396620f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0.9082]),\n",
       " tensor([0.5955]),\n",
       " tensor([0.8921]),\n",
       " tensor([0.4336]),\n",
       " tensor([0.2668]),\n",
       " tensor([0.2839]),\n",
       " tensor([0.0928]),\n",
       " tensor([0.8578]),\n",
       " tensor([0.8729])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained model if it is not loaded\n",
    "if isinstance(model_2D, str):\n",
    "    model_2D = load_trained_model(\"D-MPNN\", model_2D)\n",
    "    model_2D.eval()\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", logger=False, max_epochs=-1)\n",
    "# apply it\n",
    "dl = DataLoader(data, collate_fn=collate_fn)\n",
    "trainer.predict(model_2D, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc38fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
